{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444fb4e5",
   "metadata": {},
   "source": [
    "First we need to read the data from the csv file with headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1f3a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- read.csv(\"Desktop/weather_data_24hr_HI.csv\", header = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d356b3",
   "metadata": {},
   "source": [
    "Feature Selection has been done previously and we are just selecting the rows containing the relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc520b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selection completed\n",
    "#remove null row\n",
    "data <- data[-4265,]\n",
    "#remove columns based on feature selection\n",
    "data <- data[,c(3,4,6,8,27,29)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473d22dc",
   "metadata": {},
   "source": [
    "We perform max-min normalisation so that the gradient descent converges quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7045c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to normalize the data (max-min normalization)\n",
    "data$maxtempC <- (data$maxtempC-min(data$maxtempC))/(max(data$maxtempC)-min(data$maxtempC))\n",
    "data$avgtempC <- (data$avgtempC-min(data$avgtempC))/(max(data$avgtempC)-min(data$avgtempC))\n",
    "data$mintempC <- (data$mintempC-min(data$mintempC))/(max(data$mintempC)-min(data$mintempC))\n",
    "data$WindChillC <- (data$WindChillC-min(data$WindChillC))/(max(data$WindChillC)-min(data$WindChillC))\n",
    "data$DewPointC <- (data$DewPointC-min(data$DewPointC))/(max(data$DewPointC)-min(data$DewPointC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a76eb4",
   "metadata": {},
   "source": [
    "We split our data into training and testing datasets. Note that the idea here is that there is a lag in the different variables and we are using this lag to be able to predict tomorrow's temperature based on previous days, temperature, wind chill, and dew point data. Thus, the neural network we will construct has an auoregressive componenet to it because when we predict the only information we have is knowledge of our past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e8a2585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    }
   ],
   "source": [
    "#Data partition to divide our data into training anad testing data (70% training 30% testing)\n",
    "#we set seed in order to be able to repeat the learning\n",
    "set.seed(222)\n",
    "ind <- sample(2,nrow(data), replace = T, prob =c(0.7,0.3))\n",
    "training <- data[ind==1,]\n",
    "testing <- data[ind==2,]\n",
    "#install the neural network packages in R\n",
    "install.packages(\"neuralnet\")\n",
    "library(neuralnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b3879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a neural network n trained on the training data\n",
    "#This neural network has the error function as the sum of squared error\n",
    "#It has the activation function as the sigmoid function\n",
    "#It has 2 hidden layers\n",
    "n <- neuralnet(HeatIndexC~.,\n",
    "               data = training,\n",
    "               hidden = 2,\n",
    "               stepmax = 9999999,\n",
    "               err.fct ='sse',\n",
    "               act.fct = 'tanh',\n",
    "               linear.output = T)\n",
    "n\n",
    "#We plot our trained neural network\n",
    "plot(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283842c4",
   "metadata": {},
   "source": [
    "We now test for the accuracy of the neural network that we constructed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate the RMS error for our neural network on the training and testing dataset\n",
    "\n",
    "output <-compute(n, training)\n",
    "p1 <- output$net.result\n",
    "sqrt(sum((training$HeatIndexC-p1)^2)/nrow(training))\n",
    "max((training$HeatIndexC-p1))\n",
    "output <- compute(n, testing)\n",
    "p2 <- output$net.result\n",
    "sqrt(sum((testing$HeatIndexC-p2)^2)/nrow(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba2ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
